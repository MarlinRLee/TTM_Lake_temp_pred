{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 7 Tiny time mixer code. This should work on correctly set up data but I do not have our data so I can not vouch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Adapt real code from https://github.com/ibm-granite/granite-tsfm/blob/main/notebooks/tutorial/ttm_channel_mix_finetuning.ipynb\n",
    "\n",
    "### TODO Get real data into Tidy CSV format (ie each row is a column)\n",
    "\n",
    "### Current code is from https://colab.research.google.com/github/ibm-granite/granite-tsfm/blob/main/notebooks/hfdemo/ttm_getting_started.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda update -n base -c defaults conda -y\n",
    "! conda install lxml -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install pytorch pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "#! pip install \"tsfm_public[notebooks] @ git+https://github.com/ibm-granite/granite-tsfm.git@v0.2.14\" -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
    "from transformers.integrations import INTEGRATION_TO_CALLBACK\n",
    "\n",
    "from tsfm_public import TrackingCallback, count_parameters, load_dataset\n",
    "from tsfm_public.toolkit.get_model import get_model\n",
    "from tsfm_public.toolkit.lr_finder import optimal_lr_finder\n",
    "from tsfm_public.toolkit.visualization import plot_predictions\n",
    "\n",
    "from tsfm_public import (\n",
    "    TimeSeriesPreprocessor,\n",
    "    TrackingCallback,\n",
    "    count_parameters,\n",
    "    get_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization took: 2.46 ms\n",
      "Type conversion took: 3.37 ms\n",
      "Parser memory cleanup took: 0.00 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#1995\n",
    "url = \"https://apps.glerl.noaa.gov/erddap/griddap/GLSEA_GCS.csvp?sst%5B(1995-01-01T12:00:00Z):1:(2023-12-31T12:00:00Z)%5D%5B(42.05651963):1:(42.05649963)%5D%5B(-87.66870036):1:(-87.66867036)%5D\"\n",
    "data = pd.read_csv(url, on_bad_lines = \"warn\", delimiter=\",\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date   SST\n",
      "0 1995-01-01 12:00:00+00:00  4.49\n",
      "1 1995-01-02 12:00:00+00:00  4.43\n",
      "2 1995-01-03 12:00:00+00:00  4.35\n",
      "3 1995-01-04 12:00:00+00:00  4.26\n",
      "4 1995-01-05 12:00:00+00:00  4.17\n"
     ]
    }
   ],
   "source": [
    "SST_FN = \"GLSEA_SST_data.csv\"\n",
    "filtered_data = data.dropna()\n",
    "filtered_data['time (UTC)'] = pd.to_datetime(filtered_data['time (UTC)'])\n",
    "filtered_data = filtered_data.rename(columns={'time (UTC)': 'date', \"sst (degree_C)\": \"SST\"})\n",
    "filtered_data = filtered_data.drop([\"latitude (degrees_north)\", \"longitude (degrees_east)\"], axis=1)\n",
    "filtered_data.to_csv(SST_FN, index=False)#date\n",
    "print(filtered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed for reproducibility\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# DATA ROOT PATH\n",
    "# Make sure to download the target data (here ettm2) on the `DATA_ROOT_PATH` folder.\n",
    "# ETT is available at: https://github.com/zhouhaoyi/ETDataset/tree/main\n",
    "target_dataset = \"SST\"\n",
    "DATA_ROOT_PATH = SST_FN\n",
    "\n",
    "# Results dir\n",
    "OUT_DIR = \"ttm_finetuned_models/\"\n",
    "\n",
    "\n",
    "# Forecasting parameters\n",
    "context_length = 512\n",
    "forecast_length = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date   SST\n",
      "0 1995-01-01 12:00:00+00:00  4.49\n",
      "1 1995-01-02 12:00:00+00:00  4.43\n",
      "2 1995-01-03 12:00:00+00:00  4.35\n",
      "3 1995-01-04 12:00:00+00:00  4.26\n",
      "4 1995-01-05 12:00:00+00:00  4.17\n"
     ]
    }
   ],
   "source": [
    "# Load the data file and see the columns\n",
    "timestamp_column = \"date\"\n",
    "# timestamp_column = \"timestamp\"\n",
    "id_columns = []\n",
    "\n",
    "data = pd.read_csv(\n",
    "    DATA_ROOT_PATH,\n",
    "    parse_dates=[timestamp_column],\n",
    ")\n",
    "\n",
    "\n",
    "data[timestamp_column] = pd.to_datetime(data[timestamp_column])\n",
    "print(data.head())\n",
    "column_specifiers = {\n",
    "    \"timestamp_column\": timestamp_column,\n",
    "    \"id_columns\": id_columns,\n",
    "    \"target_columns\": [\"SST\"],\n",
    "}\n",
    "\n",
    "split_params = {\"train\": [0, 0.5], \"valid\": [0.5, 0.75], \"test\": [0.75, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp = TimeSeriesPreprocessor(\n",
    "    **column_specifiers,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_length,\n",
    "    scaling=True,\n",
    "    encode_categorical=False,\n",
    "    scaler_type=\"standard\",\n",
    ")\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = get_datasets(\n",
    "    tsp,\n",
    "    data,\n",
    "    split_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-2458115:t-140152452260160:get_model.py:get_model:Loading model from: ibm-granite/granite-timeseries-ttm-r1\n",
      "INFO:p-2458115:t-140152452260160:get_model.py:get_model:Selected prediction_length = 96\n",
      "INFO:p-2458115:t-140152452260160:get_model.py:get_model:Model loaded successfully!\n",
      "INFO:p-2458115:t-140152452260160:get_model.py:get_model:[TTM] context_len = 512, forecast_len = 96\n"
     ]
    }
   ],
   "source": [
    "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r1\"\n",
    "\n",
    "zeroshot_model = get_model(\n",
    "    TTM_MODEL_PATH,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_length,\n",
    "    prediction_channel_indices=tsp.prediction_channel_indices,\n",
    "    num_input_channels=tsp.num_input_channels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:p-2458115:t-140152452260160:other.py:check_os_kernel:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "temp_dir = tempfile.mkdtemp()\n",
    "# zeroshot_trainer\n",
    "zeroshot_trainer = Trainer(\n",
    "    model=zeroshot_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=temp_dir,\n",
    "        per_device_eval_batch_size=64,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/40 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeroshot_trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci8523",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
